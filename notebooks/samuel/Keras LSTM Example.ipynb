{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras LSTM Example\n",
    "https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 248s 1ms/step - loss: 2.0034\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"preach? they discover, these sharp onloo\"\n",
      "preach? they discover, these sharp onlood and and all a strength the conception the constituality, and still the strength the sense, the sense and and and the strength, the still the constituality of the still the seen the some and the something the conception of the subjection of the subjection of the senses and the strength of the still the streast and all the some and the conception of the sempting and the still as a strength of the \n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"preach? they discover, these sharp onloo\"\n",
      "preach? they discover, these sharp onlood intain for the suncerion of the such many the dearing intendent the the chorouble the contime of the something of the world of the still and againing, and and and and the fand to a crustion of the unthis as a wead and allither understand the exadual the deady and have the comprares--what the seeming and farting to the deserned as a proising thing\n",
      "scienting than the many and the still than is lit\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"preach? they discover, these sharp onloo\"\n",
      "preach? they discover, these sharp onlood\" this akn concained, and the\n",
      "pertoys instatubile as sedes, and alose autentouti's\" thors philosophing and thas the emedieve, and\n",
      "ralualed and amomanfnens and aisising the groving the armary forle\n",
      "suppenuss misteno. the sealt, and sympainso own\n",
      "thars the prestobed codactiin the exvetaned ammay to coural,\n",
      "the \"abtimuty--things this forg, mutho hiodin ford one mange.  thaig thought\n",
      "intaceted and am\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"preach? they discover, these sharp onloo\"\n",
      "preach? they discover, these sharp onloos subveut more despiside\" 'raygeshene, andiciftunys the\n",
      "pondingt of the the 1une\n",
      "aman is nagury. thy have\n",
      "ampithem,\n",
      " whothinosed, thint aguent belorotamnem, sreve\n",
      "in ibveu sti, a dinthon ut corsation stholly oncrenationy\n",
      "fronebol, onn-inwiteronion, betyp toourges\n",
      "of in is nhimule but.\n",
      "\n",
      "1y. on   and the roreadany of eill, fore mure but exsay viraking--inolityd olless what was?\n",
      "fore for sis-madlooin\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/1\n",
      "200285/200285 [==============================] - 263s 1ms/step - loss: 1.6438\n",
      "\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"iness is to be found in the world\n",
      "than g\"\n",
      "iness is to be found in the world\n",
      "than great and that the conditions that the selfection of the self and and that the presentional that the selfection of the conditions and and and and and and and the contradistrance of the selfection of the conditions of the self the presentality of the prose of the sense of the self the selfing of the conselves and the proporion of the self and that the self and the conditions of the selfection of the\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"iness is to be found in the world\n",
      "than g\"\n",
      "iness is to be found in the world\n",
      "than greater or a suthory and contrarial or in the and about it that every the sentle of himself that candous soul that the sense of him, and contrently its whatever its for all that the\n",
      "self into the condition of the the restruntly the serse of the containing and the solently and the interpret and love have sure present in the spirit of the contradure and that every conselves of neither.\n",
      "that is not th\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"iness is to be found in the world\n",
      "than g\"\n",
      "iness is to be found in the world\n",
      "than gos, and one that bethen embe.=--what happsion even in the manflly, are got us its hasuits of nature. that questence.--where threging and and what boveuct groubthers when things to evil \"may dod can\n",
      "this fasishoos, for a thind. it indusedness of conceent no deails understand. the divinive however, butness and their more rinds, a certain shuman from orstredal surpabli-neth, that every more intrrate,\n",
      "\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"iness is to be found in the world\n",
      "than g\"\n",
      "iness is to be found in the world\n",
      "than greatiry logil lepre(re danguling\n",
      "to1yt us mes nation, tho betaces ar4 man of\n",
      "knighless othen\n",
      "becamp their being upon their fians and manbe surpal\n",
      "kistims resention, and strentu of in this nor\n",
      "the belors in assuffe, scual to thas\n",
      "have brute everyt. how no nor possew\n",
      "knows ! the rulully, this no have for thought, but thincth\n",
      "antrowholittes undeeces our invermions tekender\n",
      "knowsdod lakcam that not pl\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/1\n",
      " 14464/200285 [=>............................] - ETA: 5:00 - loss: 1.5432"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path, encoding=\"utf-8\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "for iteration in range(1, 60):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
